{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Log-linear Language Model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Knet: Param, @diff, grad, params, value, KnetArray, logp, nll, progress\n",
    "using Random: shuffle!"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We are using data from the Penn Treebank, which is already converted into an easy-to-use\n",
    "format with \"&lt;unk&gt;\" symbols. If we were using other data we would have to do\n",
    "pre-processing and consider how to choose unknown words, etc."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "readdata(file)=[ w2i.(split(line)) for line in eachline(file) ]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Before reading the training data, we initalize the word->id dictionary with sentence\n",
    "separator \"&lt;s&gt;\" and unknown word \"&lt;unk&gt;\" symbols."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "wdict = Dict()\n",
    "w2i(x) = get!(wdict, x, 1+length(wdict)) # insert key with value len+1 if not found\n",
    "S = w2i(\"<s>\")\n",
    "UNK = w2i(\"<unk>\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Load the training data and peek at the first instance:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "trn = readdata(\"../data/ptb/train.txt\")\n",
    "first(trn)'"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Here is the reconstructed string of the first sentence:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "wstring = Array{String}(undef,length(wdict))\n",
    "for (str,id) in wdict; wstring[id] = str; end\n",
    "i2w(i) = wstring[i]\n",
    "join(i2w.(rand(trn)), \" \")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Before reading the dev/test data, we change the word->id function to return UNK for\n",
    "unknown words."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "w2i(x) = get(wdict, x, UNK)     # return UNK if x is not found"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Load the dev/test data and print the number of instances:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dev = readdata(\"../data/ptb/valid.txt\")\n",
    "tst = readdata(\"../data/ptb/test.txt\")\n",
    "length.((trn, dev, tst))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Use KnetArray to initialize parameters on GPU, use Array to initialize on CPU:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "##param(dims...) = Param(Array(0.01f0 * randn(Float32, dims...)))\n",
    "param(dims...) = Param(KnetArray(0.01f0 * randn(Float32, dims...)))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Initialize the parameters of the loglin-lm model as global variables W and b."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "nwords = length(wdict)\n",
    "N = 2  # The length of the n-gram\n",
    "W = [ param(nwords, nwords) for i in 1:N ]\n",
    "b = param(nwords)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Here is the loss function for a whole sentence:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function loss(sent)\n",
    "    slen = length(sent)\n",
    "    input = [ repeat([S],N); sent ]\n",
    "    scores = b\n",
    "    for i in 1:N\n",
    "        scores = scores .+ W[i][:,input[i:i+slen]] # @size scores (V,slen+1)\n",
    "    end\n",
    "    nll(scores, [sent; [S]])\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Here is the SGD training loop:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function train(data=trn; nepochs = 10, lr = 0.01f0)\n",
    "    for epoch in 1:nepochs\n",
    "        shuffle!(data)\n",
    "        lastloss = 0\n",
    "        for s in progress(x->lastloss, data)\n",
    "            ∇loss = @diff loss(s)\n",
    "            lastloss = value(∇loss)\n",
    "            for p in params(∇loss)\n",
    "                p .= p - lr * grad(∇loss, p)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  },
  "kernelspec": {
   "name": "julia-1.2",
   "display_name": "Julia 1.2.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
